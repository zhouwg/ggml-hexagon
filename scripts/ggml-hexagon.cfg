[general]
#0: HEXAGON_BACKEND_QNNCPU
#1: HEXAGON_BACKEND_QNNGPU
#2: HEXAGON_BACKEND_QNNNPU / HEXAGON_BACKEND_CDSP
#3: default ggml backend
hexagon_backend = 2

# enable/disable QNN's internal log
print_qnn_internal_log = 0

# enable/disable perf of op function
enable_perf = 1

# enable/disable print tensors info in op function
print_tensors_info = 0

# enable/disable dump op info in handle_op
dump_op_info = 0

#enable/disable offload fp32 & quantized type mulmat
#quatized type mulmat works fine in HWACCEL_QNN at the moment
#quatized type mulmat doesn't works fine in HWACCEL_CDSP at the moment
#this item will make mulmat performance comprision easily
enable_q_mulmat = 0

# 0: hwaccel approach through HWACCEL_QNN: offload ggml op to QNN
# 1: hwaccel approach through HWACCEL_QNN_SINGLEGRAPH: mapping entire ggml cgraph to a single QNN graph
# 2: hwaccel approach through HWACCEL_CDSP:offload ggml op to cDSP directly
# HWACCEL_QNN_SINGLEGRAPH not supported at the moment
hwaccel_approach = 2

#hwaccel approach through QNN
[qnn]
hvx_threads = 4
vtcm_size_in_mb = 8
enable_dlbc = 1
precision_mode = "fp16"

#hwaccel approach through cDSP
[cdsp]
#enable/disable rpc ion memory pool
enable_rpc_ion_mempool = 1
#enable/disable rpc dma memory pool
enable_rpc_dma_mempool = 0
