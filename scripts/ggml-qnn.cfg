[general]
#0: QNN-CPU backend
#1: QNN-GPU backend
#2: QNN-NPU(htp) backend
#3: default ggml backend
qnn_backend = 2

# enable/disable QNN's internal log
print_qnn_internal_log = 0

# enable/disable perf of op function
enable_perf = 0

# enable/disable print tensors info in op function
print_tensors_info = 0

# enable/disable dump op info in handle_op
dump_op_info = 0

# 0: general approach,similar to ggml-sycl or ggml-cann
# 1: mapping entire ggml cgraph to QNN graph
inference_approach = 0

[npu]
hvx_threads = 4
vtcm_size_in_mb = 8
enable_dlbc = 1
precision_mode = "fp16"
